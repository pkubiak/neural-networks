{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23000, 250)\n",
      "Tensor(\"Gather:0\", shape=(?, 250, 50), dtype=float32)\n",
      "[<tf.Tensor 'unstack:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:1' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:2' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:3' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:4' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:5' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:6' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:7' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:8' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:9' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:10' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:11' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:12' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:13' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:14' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:15' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:16' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:17' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:18' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:19' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:20' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:21' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:22' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:23' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:24' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:25' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:26' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:27' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:28' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:29' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:30' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:31' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:32' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:33' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:34' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:35' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:36' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:37' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:38' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:39' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:40' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:41' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:42' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:43' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:44' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:45' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:46' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:47' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:48' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:49' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:50' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:51' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:52' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:53' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:54' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:55' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:56' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:57' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:58' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:59' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:60' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:61' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:62' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:63' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:64' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:65' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:66' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:67' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:68' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:69' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:70' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:71' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:72' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:73' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:74' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:75' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:76' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:77' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:78' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:79' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:80' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:81' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:82' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:83' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:84' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:85' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:86' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:87' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:88' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:89' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:90' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:91' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:92' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:93' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:94' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:95' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:96' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:97' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:98' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:99' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:100' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:101' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:102' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:103' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:104' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:105' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:106' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:107' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:108' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:109' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:110' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:111' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:112' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:113' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:114' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:115' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:116' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:117' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:118' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:119' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:120' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:121' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:122' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:123' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:124' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:125' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:126' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:127' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:128' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:129' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:130' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:131' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:132' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:133' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:134' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:135' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:136' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:137' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:138' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:139' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:140' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:141' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:142' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:143' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:144' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:145' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:146' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:147' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:148' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:149' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:150' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:151' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:152' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:153' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:154' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:155' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:156' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:157' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:158' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:159' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:160' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:161' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:162' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:163' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:164' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:165' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:166' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:167' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:168' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:169' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:170' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:171' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:172' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:173' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:174' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:175' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:176' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:177' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:178' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:179' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:180' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:181' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:182' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:183' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:184' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:185' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:186' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:187' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:188' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:189' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:190' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:191' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:192' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:193' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:194' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:195' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:196' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:197' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:198' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:199' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:200' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:201' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:202' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:203' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:204' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:205' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:206' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:207' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:208' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:209' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:210' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:211' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:212' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:213' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:214' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:215' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:216' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:217' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:218' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:219' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:220' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:221' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:222' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:223' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:224' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:225' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:226' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:227' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:228' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:229' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:230' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:231' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:232' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:233' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:234' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:235' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:236' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:237' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:238' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:239' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:240' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:241' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:242' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:243' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:244' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:245' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:246' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:247' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:248' shape=(?, 50) dtype=float32>, <tf.Tensor 'unstack:249' shape=(?, 50) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    @author: Paweł Kubiak\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Load words list\n",
    "words = np.load('wordsList.npy').tolist()\n",
    "words = [word.decode('UTF-8') for word in words]\n",
    "word_vectors = np.load('wordVectors.npy')\n",
    "\n",
    "# Load word2vec embeding\n",
    "train_x = np.load('reviews_train_x.npy')\n",
    "train_y = np.load('reviews_train_y.npy')\n",
    "test_x = np.load('reviews_test_x.npy')\n",
    "test_y = np.load('reviews_test_y.npy')\n",
    "\n",
    "print(train_x.shape)\n",
    "\n",
    "# Consts\n",
    "TIME_STEPS = 250\n",
    "BATCH_SIZE = 256\n",
    "STATE_SIZE = 200\n",
    "TRAIN_STEPS = 100\n",
    "LSTM_LAYERS = 3\n",
    "\n",
    "# Data loaders\n",
    "x_input = tf.placeholder(tf.int64, shape = (None, TIME_STEPS))\n",
    "y_input = tf.placeholder(tf.int64, shape = (None, 2))\n",
    "\n",
    "x_embed = tf.gather(word_vectors, x_input)\n",
    "print(x_embed)\n",
    "x_unpack = tf.unstack(x_embed, TIME_STEPS, 1)\n",
    "print(x_unpack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(words[2])\n",
    "words[0] = ''\n",
    "words[399999] = '???'\n",
    "# 0 - nothing\n",
    "# 399999 - unk\n",
    "def vec2sent(vec):\n",
    "    return ' '.join(map(lambda i: words[i], vec)).strip() \n",
    "\n",
    "def evaluate(pred, x, y):\n",
    "    count = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == 0:\n",
    "            count += 1\n",
    "            print(vec2sent(x[i]), 'POSITIVE' if y[i][0] else 'NEGATIVE')\n",
    "            if count >= 5:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  @params input\\n  @params learning<True/False> are we learning or testing?\\n  @params params<Dictionary>\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "  @params input\n",
    "  @params learning<True/False> are we learning or testing?\n",
    "  @params params<Dictionary>\n",
    "\"\"\"\n",
    "# def RNN(x, learning):\n",
    "    \n",
    "# #     lstm = tf.contrib.rnn.LSTMCell(STATE_SIZE)\n",
    "    \n",
    "# #     lstm = tf.contrib.rnn.MultiRNNCell(\n",
    "# #         [tf.contrib.rnn.LSTMCell(STATE_SIZE) for _ in range(LSTM_LAYERS)])\n",
    "#     layers = []\n",
    "#     for _ in range(LSTM_LAYERS):\n",
    "#         cell = tf.contrib.rnn.GRUCell(STATE_SIZE)\n",
    "#         # variational_recurrent=True, input_size=STATE_SIZE, dtype=tf.float32 - pogarsza wyniki\n",
    "#         wrap = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0 - dropout, state_keep_prob=1.0 - 0.5*dropout)\n",
    "#         layers.append(wrap)\n",
    "        \n",
    "#     lstm = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "        \n",
    "#     outputs, states = tf.contrib.rnn.static_rnn(lstm, x, dtype=tf.float32)\n",
    "    \n",
    "#     dense = tf.layers.dense(outputs[-1], 2)\n",
    "    \n",
    "#     return dense\n",
    "\n",
    "\n",
    "\n",
    "# dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "# rnn = RNN(x_unpack, dropout)\n",
    "# prediction = tf.argmax(tf.nn.softmax(rnn), 1)\n",
    "\n",
    "# loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=rnn, labels=y_input))\n",
    "# #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss_op)\n",
    "\n",
    "# global_step = tf.Variable(0, trainable=False)\n",
    "# starter_learning_rate = 1e-3\n",
    "# learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "#                                            90, 0.96, staircase=True)\n",
    "\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_op, global_step = global_step)\n",
    "\n",
    "# correct_pred = tf.equal(prediction, tf.argmax(y_input, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# verbose = False\n",
    "\n",
    "# t0 = time.time()\n",
    "# with tf.Session() as session:\n",
    "#     session.run(init)\n",
    "\n",
    "#     for i in range(100):\n",
    "#         idx = np.arange(len(train_x))\n",
    "#         np.random.shuffle(idx)\n",
    "#         idx = np.array_split(idx, (len(idx)+BATCH_SIZE-1)//BATCH_SIZE)\n",
    "\n",
    "#         accs = []\n",
    "#         for step in tqdm(idx, leave = False):\n",
    "# #             step = np.random.choice(len(train_x), BATCH_SIZE)\n",
    "#             x_batch, y_batch = train_x[step], train_y[step]\n",
    "#             _, acc = session.run([optimizer, accuracy], feed_dict = {x_input: x_batch, y_input: y_batch, dropout: 0.2})\n",
    "#             accs.append(acc)\n",
    "#         acc_train = 1.0*sum(accs)/len(accs)\n",
    "        \n",
    "#         lr, pred, acc = session.run([learning_rate, correct_pred, accuracy], feed_dict = {x_input: test_x, y_input: test_y, dropout: 0.0})\n",
    "        \n",
    "#         dt = time.time() - t0\n",
    "#         sys.stderr.flush()\n",
    "#         sys.stdout.flush()\n",
    "#         l = list(map(lambda i: 0 if pred[i] else np.count_nonzero(test_x[i]), range(len(pred))))\n",
    "#         l = 1.0*sum(l) / np.count_nonzero(l)\n",
    "#         print(\"{} acc: {:.2f} acc_train: {:.2f} time: {:.2f}, lr: {}, len: {}\".format(i, 100*acc, 100*acc_train, dt, lr, l))\n",
    "        \n",
    "# #         if i>5:\n",
    "# #             evaluate(pred, test_x, test_y)\n",
    "#         sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  1\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.0, 'state_size': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception in thread Thread-27:                 \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/storage/users/z1077883/ml/.venv/lib/python3.5/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/mnt/storage/users/z1077883/ml/.venv/lib/python3.5/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  (0.0, 'GRU', 1, 25, 0.1) ACC= 0.803\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.15, 'state_size': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  (0.0, 'GRU', 1, 25, 0.15) ACC= 0.795\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.3, 'state_size': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  (0.0, 'GRU', 1, 25, 0.3) ACC= 0.7885\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.0, 'state_size': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  (0.0, 'GRU', 1, 50, 0.0) ACC= 0.8115\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.1, 'state_size': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  (0.0, 'GRU', 1, 50, 0.1) ACC= 0.822\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.15, 'state_size': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  (0.0, 'GRU', 1, 50, 0.15) ACC= 0.8285\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.3, 'state_size': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  (0.0, 'GRU', 1, 50, 0.3) ACC= 0.821\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.0, 'state_size': 120}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:  (0.0, 'GRU', 1, 120, 0.0) ACC= 0.833\n",
      "Building:  {'state_dropout': 0.0, 'cell_type': 'GRU', 'layer_count': 1, 'dropout': 0.1, 'state_size': 120}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "tf.reset_default_graph()\n",
    "# Factory for different LSTM cells\n",
    "def cell(ctype, state_size, dropout, state_dropout, training):\n",
    "    if ctype != 'NORM':\n",
    "        if ctype == 'BASIC':\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(state_size)\n",
    "\n",
    "        # Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078).\n",
    "        if ctype == 'GRU':\n",
    "            cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "\n",
    "        # Long short-term memory unit (LSTM) recurrent network cell.\n",
    "        if ctype == 'LSTM':\n",
    "            cell = tf.contrib.rnn.LSTMCell(state_size)\n",
    "\n",
    "        # Long short-term memory unit (LSTM) recurrent network cell with peephholes\n",
    "        if ctype == 'LSTM-PEEP':\n",
    "            cell = tf.contrib.rnn.LSTMCell(state_size, use_peepholes=True)\n",
    "        \n",
    "        return tf.contrib.rnn.DropoutWrapper(\n",
    "            cell,\n",
    "            output_keep_prob = tf.where(training, 1.0 - dropout, 1.0),\n",
    "            state_keep_prob = tf.where(training, 1.0 - state_dropout, 1.0)\n",
    "        )\n",
    "    else:\n",
    "        return tf.contrib.rnn.LayerNormBasicLSTMCell(\n",
    "            state_size,\n",
    "            dropout_keep_prob = tf.where(training, 1 - dropout, 1.0)\n",
    "        )\n",
    "    \n",
    "    \n",
    "def network(input, output, training, params):\n",
    "    \n",
    "    \n",
    "    layers = []\n",
    "    for _ in range(params['layer_count']):\n",
    "        layers.append(cell(params['cell_type'], params['state_size'], params['dropout'], params['state_dropout'], training))\n",
    "    \n",
    "    lstm = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm, input, dtype=tf.float32)\n",
    "    dense = tf.layers.dense(outputs[-1], 2)\n",
    "    \n",
    "#     prediction = tf.argmax(tf.nn.softmax(dense), 1)\n",
    "    \n",
    "#     loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=dense, labels=output))\n",
    "    \n",
    "    return dense\n",
    "\n",
    "\n",
    "\n",
    "def hyper_network(hparams):\n",
    "    for product in itertools.product(*hparams.values()):\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        x_input = tf.placeholder(tf.int64, shape = (None, TIME_STEPS))\n",
    "        y_input = tf.placeholder(tf.int64, shape = (None, 2))\n",
    "\n",
    "        x_embed = tf.gather(word_vectors, x_input)\n",
    "        x_unpack = tf.unstack(x_embed, TIME_STEPS, 1)\n",
    "        \n",
    "        training = tf.placeholder(tf.bool)\n",
    "    \n",
    "        params = {key: product[i] for i, key in enumerate(hparams.keys())}\n",
    "        print('Building: ', params)\n",
    "        \n",
    "        yield (product, network(x_unpack, y_input, training, params), x_input, y_input, training)\n",
    "\n",
    "    \n",
    "def hyper_evaluate(network, x_input, y_input, training, steps=5):\n",
    "#     tf.reset_default_graph()\n",
    "    prediction = tf.argmax(tf.nn.softmax(network), 1)\n",
    "\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network, labels=y_input))\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 1e-3\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                               90, 0.96, staircase=True)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_op, global_step = global_step)\n",
    "\n",
    "    correct_pred = tf.equal(prediction, tf.argmax(y_input, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(init)\n",
    "#         print('Init')\n",
    "        for i in range(steps):\n",
    "            #print('Step: ', i)\n",
    "            idx = np.arange(len(train_x))\n",
    "            np.random.shuffle(idx)\n",
    "            idx = np.array_split(idx, (len(idx)+BATCH_SIZE-1)//BATCH_SIZE)\n",
    "\n",
    "            accs = []\n",
    "            for step in tqdm(idx, leave = False):\n",
    "    #             step = np.random.choice(len(train_x), BATCH_SIZE)\n",
    "                x_batch, y_batch = train_x[step], train_y[step]\n",
    "                _, acc = session.run([optimizer, accuracy], feed_dict = {x_input: x_batch, y_input: y_batch, training: True})\n",
    "                accs.append(acc)\n",
    "            acc_train = 1.0*sum(accs)/len(accs)\n",
    "            #print(acc_train)\n",
    "\n",
    "        _, _, acc = session.run([learning_rate, correct_pred, accuracy], feed_dict = {x_input: test_x, y_input: test_y, training: False}) \n",
    "        return acc\n",
    "\n",
    "# def evaluate(net):\n",
    "#     pass\n",
    "\n",
    "params = {\n",
    "    'dropout': [0.0, 0.1, 0.15, 0.3],\n",
    "    'state_dropout': [0.0, 0.1, 0.2, 0.3],\n",
    "    'cell_type': ['GRU', 'LSTM', 'LSTM-PEEP', 'NORM'],\n",
    "    'layer_count': [1, 2, 3],\n",
    "    'state_size': [25, 50, 120, 300]\n",
    "}\n",
    "\n",
    "for round in range(5):\n",
    "    print('Round: ', round+1)\n",
    "    for p, net, x, y, t in hyper_network(params):\n",
    "        print('RESULTS: ', p, 'ACC=', hyper_evaluate(net, x, y, t))\n",
    "\n",
    "# print(len(list(hyper_network(params))))\n",
    "\n",
    "# for i, net in enumerate(hyper_network(params)):\n",
    "#     acc = evaluate(net)\n",
    "#     print(i, acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
